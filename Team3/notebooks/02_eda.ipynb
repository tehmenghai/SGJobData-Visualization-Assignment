{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Team3 - Singapore Jobs Analytics**\n",
    "\n",
    "This notebook explores the cleaned dataset to discover key patterns and anomalies that inform dashboard design.\n",
    "\n",
    "**Areas of Exploration:**\n",
    "- Data overview and summary statistics\n",
    "- Distribution of job postings by salary, experience, categories\n",
    "- Salary deep dive across categories and experience bands\n",
    "- Temporal trends in job postings\n",
    "- Company analysis and long-tail distribution\n",
    "- Engagement patterns (views, applications, application rate)\n",
    "\n",
    "**Tools:** DuckDB (in-memory OLAP), Pandas, Matplotlib, Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme(style='whitegrid', palette='muted')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "con = duckdb.connect(':memory:')\n",
    "print('DuckDB version:', duckdb.__version__)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Load data: try cleaned parquet first, fall back to raw CSV with inline cleaning\nimport os\n\nif os.path.exists('../data/processed/jobs_cleaned.parquet'):\n    con.execute(\"\"\"\n        CREATE TABLE jobs_raw AS\n        SELECT * FROM read_parquet('../data/processed/jobs_cleaned.parquet')\n    \"\"\")\n    print('Loaded from cleaned parquet (output of 01_data_cleaning)')\nelse:\n    print('jobs_cleaned.parquet not found — loading from raw CSV with inline cleaning...')\n    con.execute(\"\"\"\n        CREATE TABLE jobs_raw AS\n        SELECT * FROM read_csv_auto('../data/raw/SGJobData.csv', header=true, sample_size=-1)\n        WHERE metadata_jobPostId IS NOT NULL\n          AND NOT (salary_minimum = 1 AND salary_maximum = 1 AND average_salary = 1)\n    \"\"\")\n    print('Loaded from raw CSV with cleaning applied (removed NULL IDs + placeholder salaries)')\n\nrow_count = con.execute('SELECT COUNT(*) FROM jobs_raw').fetchone()[0]\nprint(f'Total rows: {row_count:,}')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create analytical views for EDA\n",
    "# jobs_base: normalize salary, cast dates, compute application rate\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW jobs_base AS\n",
    "SELECT\n",
    "  metadata_jobPostId as job_id,\n",
    "  title,\n",
    "  postedCompany_name as company_name,\n",
    "  salary_minimum,\n",
    "  salary_maximum,\n",
    "  salary_type,\n",
    "  CASE\n",
    "    WHEN salary_minimum IS NOT NULL AND salary_maximum IS NOT NULL\n",
    "    THEN (salary_minimum + salary_maximum) / 2\n",
    "    ELSE average_salary\n",
    "  END as avg_salary,\n",
    "  salary_maximum - salary_minimum as salary_range,\n",
    "  minimumYearsExperience as min_experience,\n",
    "  numberOfVacancies as vacancies,\n",
    "  status_jobStatus as job_status,\n",
    "  TRY_CAST(metadata_originalPostingDate AS DATE) as posting_date,\n",
    "  TRY_CAST(metadata_expiryDate AS DATE) as expiry_date,\n",
    "  metadata_totalNumberJobApplication as applications,\n",
    "  metadata_totalNumberOfView as views,\n",
    "  CASE\n",
    "    WHEN metadata_totalNumberOfView > 0\n",
    "    THEN CAST(metadata_totalNumberJobApplication AS FLOAT) / metadata_totalNumberOfView\n",
    "    ELSE NULL\n",
    "  END as application_rate,\n",
    "  metadata_repostCount as repost_count,\n",
    "  categories\n",
    "FROM jobs_raw\n",
    "WHERE metadata_jobPostId IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "# jobs_enriched: add salary bands, experience bands, time dimensions\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW jobs_enriched AS\n",
    "SELECT\n",
    "  *,\n",
    "  CASE\n",
    "    WHEN avg_salary < 3000 THEN '< 3K'\n",
    "    WHEN avg_salary < 5000 THEN '3K - 5K'\n",
    "    WHEN avg_salary < 8000 THEN '5K - 8K'\n",
    "    WHEN avg_salary < 12000 THEN '8K - 12K'\n",
    "    WHEN avg_salary < 20000 THEN '12K - 20K'\n",
    "    ELSE '20K+'\n",
    "  END as salary_band,\n",
    "  CASE\n",
    "    WHEN min_experience IS NULL OR min_experience <= 2 THEN 'Entry (0-2 years)'\n",
    "    WHEN min_experience <= 5 THEN 'Mid (3-5 years)'\n",
    "    WHEN min_experience <= 10 THEN 'Senior (6-10 years)'\n",
    "    ELSE 'Executive (10+ years)'\n",
    "  END as experience_band,\n",
    "  EXTRACT(YEAR FROM posting_date) as posting_year,\n",
    "  EXTRACT(MONTH FROM posting_date) as posting_month,\n",
    "  EXTRACT(QUARTER FROM posting_date) as posting_quarter,\n",
    "  EXTRACT(DOW FROM posting_date) as posting_day_of_week,\n",
    "  expiry_date - posting_date as days_active\n",
    "FROM jobs_base\n",
    "WHERE avg_salary IS NOT NULL AND avg_salary > 0\n",
    "\"\"\")\n",
    "\n",
    "# jobs_categories: flatten JSON categories array\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW jobs_categories AS\n",
    "WITH indices AS (\n",
    "  SELECT 0 as idx UNION ALL SELECT 1 UNION ALL SELECT 2 UNION ALL SELECT 3 UNION ALL SELECT 4\n",
    "  UNION ALL SELECT 5 UNION ALL SELECT 6 UNION ALL SELECT 7 UNION ALL SELECT 8 UNION ALL SELECT 9\n",
    ")\n",
    "SELECT\n",
    "  j.job_id, j.title, j.company_name,\n",
    "  CAST(json_extract_string(json_extract(j.categories::JSON, '$[' || i.idx || ']'), '$.id') AS INTEGER) as category_id,\n",
    "  json_extract_string(json_extract(j.categories::JSON, '$[' || i.idx || ']'), '$.category') as category_name,\n",
    "  j.salary_minimum, j.salary_maximum, j.avg_salary, j.posting_date,\n",
    "  j.job_status, j.min_experience, j.vacancies, j.experience_band, j.salary_band\n",
    "FROM jobs_enriched j\n",
    "CROSS JOIN indices i\n",
    "WHERE j.categories IS NOT NULL AND j.categories != '' AND j.categories != '[]'\n",
    "  AND i.idx < json_array_length(j.categories::JSON)\n",
    "  AND json_extract(j.categories::JSON, '$[' || i.idx || ']') IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "# Verify view counts\n",
    "for view in ['jobs_base', 'jobs_enriched', 'jobs_categories']:\n",
    "    cnt = con.execute(f'SELECT COUNT(*) FROM {view}').fetchone()[0]\n",
    "    print(f'{view}: {cnt:,} rows')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Schema and data types\n",
    "schema = con.execute('DESCRIBE jobs_raw').fetchdf()\n",
    "schema"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Preview first 5 rows\n",
    "preview = con.execute('SELECT * FROM jobs_raw LIMIT 5').fetchdf()\n",
    "preview"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Summary statistics of numeric columns\n",
    "numeric_stats = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        COUNT(*) as total_rows,\n",
    "        AVG(salary_minimum) as avg_salary_min,\n",
    "        AVG(salary_maximum) as avg_salary_max,\n",
    "        AVG(average_salary) as avg_salary,\n",
    "        AVG(minimumYearsExperience) as avg_experience,\n",
    "        AVG(numberOfVacancies) as avg_vacancies,\n",
    "        AVG(metadata_totalNumberJobApplication) as avg_applications,\n",
    "        AVG(metadata_totalNumberOfView) as avg_views\n",
    "    FROM jobs_raw\n",
    "\"\"\").fetchdf()\n",
    "numeric_stats.T.rename(columns={0: 'Value'})"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Detailed summary statistics\n",
    "detailed_stats = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        'salary_minimum' as field,\n",
    "        MIN(salary_minimum) as min_val,\n",
    "        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY salary_minimum) as p25,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY salary_minimum) as median,\n",
    "        AVG(salary_minimum) as mean,\n",
    "        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY salary_minimum) as p75,\n",
    "        MAX(salary_minimum) as max_val,\n",
    "        COUNT(salary_minimum) as non_null\n",
    "    FROM jobs_raw\n",
    "    UNION ALL\n",
    "    SELECT 'salary_maximum',\n",
    "        MIN(salary_maximum), PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY salary_maximum),\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY salary_maximum),\n",
    "        AVG(salary_maximum), PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY salary_maximum),\n",
    "        MAX(salary_maximum), COUNT(salary_maximum)\n",
    "    FROM jobs_raw\n",
    "    UNION ALL\n",
    "    SELECT 'average_salary',\n",
    "        MIN(average_salary), PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY average_salary),\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY average_salary),\n",
    "        AVG(average_salary), PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY average_salary),\n",
    "        MAX(average_salary), COUNT(average_salary)\n",
    "    FROM jobs_raw\n",
    "    UNION ALL\n",
    "    SELECT 'minimumYearsExperience',\n",
    "        MIN(minimumYearsExperience), PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY minimumYearsExperience),\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY minimumYearsExperience),\n",
    "        AVG(minimumYearsExperience), PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY minimumYearsExperience),\n",
    "        MAX(minimumYearsExperience), COUNT(minimumYearsExperience)\n",
    "    FROM jobs_raw\n",
    "    UNION ALL\n",
    "    SELECT 'numberOfVacancies',\n",
    "        MIN(numberOfVacancies), PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY numberOfVacancies),\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY numberOfVacancies),\n",
    "        AVG(numberOfVacancies), PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY numberOfVacancies),\n",
    "        MAX(numberOfVacancies), COUNT(numberOfVacancies)\n",
    "    FROM jobs_raw\n",
    "\"\"\").fetchdf()\n",
    "detailed_stats"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Salary distribution: histogram + box plot (cap at $50K to handle outliers)\n",
    "salary_data = con.execute(\"\"\"\n",
    "    SELECT avg_salary FROM jobs_enriched\n",
    "    WHERE avg_salary > 0 AND avg_salary < 50000\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(salary_data['avg_salary'], bins=50, color='#2563EB', edgecolor='white', alpha=0.8)\n",
    "axes[0].set_xlabel('Average Salary ($)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Salary Distribution (capped at $50K)')\n",
    "axes[0].axvline(salary_data['avg_salary'].median(), color='#EF4444', linestyle='--', label=f\"Median: ${salary_data['avg_salary'].median():,.0f}\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].boxplot(salary_data['avg_salary'], vert=True, patch_artist=True,\n",
    "                boxprops=dict(facecolor='#2563EB', alpha=0.6),\n",
    "                medianprops=dict(color='#EF4444', linewidth=2))\n",
    "axes[1].set_ylabel('Average Salary ($)')\n",
    "axes[1].set_title('Salary Box Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Salary stats (capped at $50K):\")\n",
    "print(f\"  Mean:   ${salary_data['avg_salary'].mean():,.0f}\")\n",
    "print(f\"  Median: ${salary_data['avg_salary'].median():,.0f}\")\n",
    "print(f\"  Std:    ${salary_data['avg_salary'].std():,.0f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Salary band distribution\n",
    "SALARY_BAND_ORDER = ['< 3K', '3K - 5K', '5K - 8K', '8K - 12K', '12K - 20K', '20K+']\n",
    "\n",
    "salary_bands = con.execute(\"\"\"\n",
    "    SELECT salary_band, COUNT(*) as count\n",
    "    FROM jobs_enriched\n",
    "    GROUP BY salary_band\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "salary_bands['salary_band'] = pd.Categorical(salary_bands['salary_band'], categories=SALARY_BAND_ORDER, ordered=True)\n",
    "salary_bands = salary_bands.sort_values('salary_band')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bars = ax.bar(salary_bands['salary_band'].astype(str), salary_bands['count'],\n",
    "              color=['#2563EB', '#10B981', '#F59E0B', '#8B5CF6', '#EC4899', '#06B6D4'])\n",
    "ax.set_xlabel('Salary Band')\n",
    "ax.set_ylabel('Number of Jobs')\n",
    "ax.set_title('Job Distribution by Salary Band')\n",
    "for bar in bars:\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height(),\n",
    "            f'{int(bar.get_height()):,}', ha='center', va='bottom', fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Experience band distribution + raw experience histogram\n",
    "EXP_BAND_ORDER = ['Entry (0-2 years)', 'Mid (3-5 years)', 'Senior (6-10 years)', 'Executive (10+ years)']\n",
    "\n",
    "exp_bands = con.execute(\"\"\"\n",
    "    SELECT experience_band, COUNT(*) as count\n",
    "    FROM jobs_enriched\n",
    "    GROUP BY experience_band\n",
    "\"\"\").fetchdf()\n",
    "exp_bands['experience_band'] = pd.Categorical(exp_bands['experience_band'], categories=EXP_BAND_ORDER, ordered=True)\n",
    "exp_bands = exp_bands.sort_values('experience_band')\n",
    "\n",
    "exp_raw = con.execute(\"\"\"\n",
    "    SELECT min_experience FROM jobs_enriched\n",
    "    WHERE min_experience IS NOT NULL AND min_experience <= 30\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].bar(exp_bands['experience_band'].astype(str), exp_bands['count'],\n",
    "            color=['#10B981', '#2563EB', '#F59E0B', '#8B5CF6'])\n",
    "axes[0].set_xlabel('Experience Band')\n",
    "axes[0].set_ylabel('Number of Jobs')\n",
    "axes[0].set_title('Job Distribution by Experience Band')\n",
    "axes[0].tick_params(axis='x', rotation=15)\n",
    "\n",
    "axes[1].hist(exp_raw['min_experience'], bins=30, color='#2563EB', edgecolor='white', alpha=0.8)\n",
    "axes[1].set_xlabel('Minimum Years of Experience')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Raw Experience Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Vacancies distribution\n",
    "vacancies = con.execute(\"\"\"\n",
    "    SELECT vacancies FROM jobs_enriched\n",
    "    WHERE vacancies IS NOT NULL AND vacancies > 0 AND vacancies <= 50\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(vacancies['vacancies'], bins=50, color='#10B981', edgecolor='white', alpha=0.8)\n",
    "ax.set_xlabel('Number of Vacancies')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Vacancies per Job Posting (capped at 50)')\n",
    "ax.axvline(vacancies['vacancies'].median(), color='#EF4444', linestyle='--',\n",
    "           label=f\"Median: {vacancies['vacancies'].median():.0f}\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Job status distribution\n",
    "status_dist = con.execute(\"\"\"\n",
    "    SELECT job_status, COUNT(*) as count\n",
    "    FROM jobs_base\n",
    "    WHERE job_status IS NOT NULL\n",
    "    GROUP BY job_status\n",
    "    ORDER BY count DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].barh(status_dist['job_status'], status_dist['count'], color='#2563EB')\n",
    "axes[0].set_xlabel('Count')\n",
    "axes[0].set_title('Job Status Distribution')\n",
    "\n",
    "axes[1].pie(status_dist['count'], labels=status_dist['job_status'], autopct='%1.1f%%',\n",
    "            colors=['#2563EB', '#10B981', '#F59E0B', '#8B5CF6', '#EC4899'][:len(status_dist)])\n",
    "axes[1].set_title('Job Status Proportions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Category Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Sample JSON structure preview\n",
    "sample_cats = con.execute(\"\"\"\n",
    "    SELECT categories\n",
    "    FROM jobs_raw\n",
    "    WHERE categories IS NOT NULL AND categories != '' AND categories != '[]'\n",
    "    LIMIT 3\n",
    "\"\"\").fetchdf()\n",
    "print('Sample categories JSON:')\n",
    "for i, row in sample_cats.iterrows():\n",
    "    print(f\"  Row {i}: {row['categories'][:200]}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Top 20 categories by posting volume\n",
    "top_categories = con.execute(\"\"\"\n",
    "    SELECT category_name, COUNT(*) as job_count\n",
    "    FROM jobs_categories\n",
    "    WHERE category_name IS NOT NULL\n",
    "    GROUP BY category_name\n",
    "    ORDER BY job_count DESC\n",
    "    LIMIT 20\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.barh(top_categories['category_name'][::-1], top_categories['job_count'][::-1], color='#2563EB')\n",
    "ax.set_xlabel('Number of Job Postings')\n",
    "ax.set_title('Top 20 Job Categories by Posting Volume')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Categories per job distribution\n",
    "cats_per_job = con.execute(\"\"\"\n",
    "    SELECT job_id, COUNT(*) as num_categories\n",
    "    FROM jobs_categories\n",
    "    GROUP BY job_id\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(cats_per_job['num_categories'], bins=range(1, cats_per_job['num_categories'].max() + 2),\n",
    "        color='#F59E0B', edgecolor='white', alpha=0.8, align='left')\n",
    "ax.set_xlabel('Number of Categories per Job')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Categories per Job Posting')\n",
    "ax.set_xticks(range(1, min(11, cats_per_job['num_categories'].max() + 1)))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean categories per job: {cats_per_job['num_categories'].mean():.2f}\")\n",
    "print(f\"Max categories per job: {cats_per_job['num_categories'].max()}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Salary Deep Dive"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Salary by top 10 categories (box plots)\n",
    "top10_cats = con.execute(\"\"\"\n",
    "    SELECT category_name FROM jobs_categories\n",
    "    WHERE category_name IS NOT NULL\n",
    "    GROUP BY category_name\n",
    "    ORDER BY COUNT(*) DESC\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()['category_name'].tolist()\n",
    "\n",
    "cat_salary_data = con.execute(f\"\"\"\n",
    "    SELECT category_name, avg_salary\n",
    "    FROM jobs_categories\n",
    "    WHERE category_name IN ({', '.join(f\"'{c}'\" for c in top10_cats)})\n",
    "      AND avg_salary > 0 AND avg_salary < 50000\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "cat_order = cat_salary_data.groupby('category_name')['avg_salary'].median().sort_values(ascending=False).index\n",
    "sns.boxplot(data=cat_salary_data, x='category_name', y='avg_salary', order=cat_order, ax=ax, palette='muted')\n",
    "ax.set_xlabel('Category')\n",
    "ax.set_ylabel('Average Salary ($)')\n",
    "ax.set_title('Salary Distribution by Top 10 Categories')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Mean vs Median salary by top 15 categories\n",
    "mean_median = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        category_name,\n",
    "        AVG(avg_salary) as mean_salary,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY avg_salary) as median_salary,\n",
    "        COUNT(*) as job_count\n",
    "    FROM jobs_categories\n",
    "    WHERE category_name IS NOT NULL AND avg_salary > 0 AND avg_salary < 50000\n",
    "    GROUP BY category_name\n",
    "    ORDER BY mean_salary DESC\n",
    "    LIMIT 15\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "x = range(len(mean_median))\n",
    "width = 0.35\n",
    "ax.bar([i - width/2 for i in x], mean_median['mean_salary'], width, label='Mean', color='#2563EB')\n",
    "ax.bar([i + width/2 for i in x], mean_median['median_salary'], width, label='Median', color='#10B981')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(mean_median['category_name'], rotation=45, ha='right')\n",
    "ax.set_ylabel('Salary ($)')\n",
    "ax.set_title('Mean vs Median Salary by Top 15 Categories')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Salary by experience band\n",
    "salary_by_exp = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        experience_band,\n",
    "        AVG(avg_salary) as mean_salary,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY avg_salary) as median_salary,\n",
    "        COUNT(*) as job_count\n",
    "    FROM jobs_enriched\n",
    "    WHERE avg_salary > 0 AND avg_salary < 50000\n",
    "    GROUP BY experience_band\n",
    "    ORDER BY\n",
    "        CASE experience_band\n",
    "            WHEN 'Entry (0-2 years)' THEN 1\n",
    "            WHEN 'Mid (3-5 years)' THEN 2\n",
    "            WHEN 'Senior (6-10 years)' THEN 3\n",
    "            WHEN 'Executive (10+ years)' THEN 4\n",
    "        END\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "x = range(len(salary_by_exp))\n",
    "width = 0.35\n",
    "ax.bar([i - width/2 for i in x], salary_by_exp['mean_salary'], width, label='Mean', color='#2563EB')\n",
    "ax.bar([i + width/2 for i in x], salary_by_exp['median_salary'], width, label='Median', color='#10B981')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(salary_by_exp['experience_band'])\n",
    "ax.set_ylabel('Salary ($)')\n",
    "ax.set_title('Salary by Experience Band')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Salary band vs experience band heatmap\n",
    "SALARY_BAND_ORDER = ['< 3K', '3K - 5K', '5K - 8K', '8K - 12K', '12K - 20K', '20K+']\n",
    "EXP_BAND_ORDER = ['Entry (0-2 years)', 'Mid (3-5 years)', 'Senior (6-10 years)', 'Executive (10+ years)']\n",
    "\n",
    "heatmap_data = con.execute(\"\"\"\n",
    "    SELECT salary_band, experience_band, COUNT(*) as job_count\n",
    "    FROM jobs_enriched\n",
    "    GROUP BY salary_band, experience_band\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "pivot = heatmap_data.pivot_table(index='salary_band', columns='experience_band', values='job_count', fill_value=0)\n",
    "pivot = pivot.reindex(index=SALARY_BAND_ORDER, columns=EXP_BAND_ORDER)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.heatmap(pivot, annot=True, fmt=',', cmap='YlOrRd', ax=ax)\n",
    "ax.set_title('Job Count: Salary Band vs Experience Band')\n",
    "ax.set_ylabel('Salary Band')\n",
    "ax.set_xlabel('Experience Band')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salary Insights\n",
    "\n",
    "- **Right-skewed distribution:** The salary distribution is heavily right-skewed, with a long tail of high earners. The $50K cap filters extreme outliers while preserving 99%+ of data.\n",
    "- **Mean > Median gap:** Across most categories, the mean salary exceeds the median, confirming right skew. The dashboard presents both metrics to give users a realistic picture.\n",
    "- **Clear experience-salary progression:** Salary increases monotonically with experience band, validating the 4-band classification used in the dashboard.\n",
    "- **Entry-level concentration:** The heatmap reveals that the largest job volume sits in the Entry/Mid experience bands at the 3K-8K salary range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Date range of dataset\n",
    "date_range = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        MIN(posting_date) as earliest,\n",
    "        MAX(posting_date) as latest,\n",
    "        COUNT(DISTINCT posting_date) as unique_dates,\n",
    "        DATEDIFF('day', MIN(posting_date), MAX(posting_date)) as span_days\n",
    "    FROM jobs_enriched\n",
    "    WHERE posting_date IS NOT NULL\n",
    "\"\"\").fetchdf()\n",
    "print('Date range of dataset:')\n",
    "date_range"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Monthly posting volume + avg salary (dual-axis line)\n",
    "monthly = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        DATE_TRUNC('month', posting_date) as month,\n",
    "        COUNT(*) as job_count,\n",
    "        AVG(avg_salary) as avg_salary\n",
    "    FROM jobs_enriched\n",
    "    WHERE posting_date IS NOT NULL\n",
    "    GROUP BY DATE_TRUNC('month', posting_date)\n",
    "    ORDER BY month\n",
    "\"\"\").fetchdf()\n",
    "monthly['month'] = pd.to_datetime(monthly['month'])\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "ax1.bar(monthly['month'], monthly['job_count'], width=20, alpha=0.6, color='#2563EB', label='Job Postings')\n",
    "ax1.set_xlabel('Month')\n",
    "ax1.set_ylabel('Number of Postings', color='#2563EB')\n",
    "ax1.tick_params(axis='y', labelcolor='#2563EB')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(monthly['month'], monthly['avg_salary'], color='#EF4444', linewidth=2, marker='o', markersize=4, label='Avg Salary')\n",
    "ax2.set_ylabel('Average Salary ($)', color='#EF4444')\n",
    "ax2.tick_params(axis='y', labelcolor='#EF4444')\n",
    "\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "ax1.set_title('Monthly Posting Volume & Average Salary')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Day of week posting pattern\n",
    "dow = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        posting_day_of_week as dow,\n",
    "        CASE posting_day_of_week\n",
    "            WHEN 0 THEN 'Sunday'\n",
    "            WHEN 1 THEN 'Monday'\n",
    "            WHEN 2 THEN 'Tuesday'\n",
    "            WHEN 3 THEN 'Wednesday'\n",
    "            WHEN 4 THEN 'Thursday'\n",
    "            WHEN 5 THEN 'Friday'\n",
    "            WHEN 6 THEN 'Saturday'\n",
    "        END as day_name,\n",
    "        COUNT(*) as job_count\n",
    "    FROM jobs_enriched\n",
    "    WHERE posting_day_of_week IS NOT NULL\n",
    "    GROUP BY posting_day_of_week\n",
    "    ORDER BY posting_day_of_week\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "colors = ['#F59E0B' if d in [0, 6] else '#2563EB' for d in dow['dow']]\n",
    "ax.bar(dow['day_name'], dow['job_count'], color=colors)\n",
    "ax.set_xlabel('Day of Week')\n",
    "ax.set_ylabel('Number of Postings')\n",
    "ax.set_title('Posting Volume by Day of Week (weekends highlighted in amber)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Quarterly posting volume\n",
    "quarterly = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        posting_year || '-Q' || posting_quarter as quarter,\n",
    "        COUNT(*) as job_count\n",
    "    FROM jobs_enriched\n",
    "    WHERE posting_year IS NOT NULL AND posting_quarter IS NOT NULL\n",
    "    GROUP BY posting_year, posting_quarter\n",
    "    ORDER BY posting_year, posting_quarter\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.bar(quarterly['quarter'], quarterly['job_count'], color='#10B981')\n",
    "ax.set_xlabel('Quarter')\n",
    "ax.set_ylabel('Number of Postings')\n",
    "ax.set_title('Quarterly Posting Volume')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Insights\n",
    "\n",
    "- **Weekday dominance:** Job postings are heavily concentrated on weekdays, with significantly lower volumes on weekends.\n",
    "- **Seasonal patterns:** Quarterly analysis reveals hiring cycles — volume tends to dip in certain quarters, which may align with budget cycles and public holidays.\n",
    "- **Salary stability:** Average salary remains relatively stable month-to-month despite volume fluctuations, suggesting the salary trends feature in the dashboard should use monthly granularity.\n",
    "- **Dashboard design implication:** The Opportunity Finder tab uses quarterly trends to help users identify hiring peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Company Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Top 20 companies by posting volume\n",
    "top_companies = con.execute(\"\"\"\n",
    "    SELECT company_name, COUNT(*) as job_count\n",
    "    FROM jobs_enriched\n",
    "    WHERE company_name IS NOT NULL\n",
    "    GROUP BY company_name\n",
    "    ORDER BY job_count DESC\n",
    "    LIMIT 20\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.barh(top_companies['company_name'][::-1], top_companies['job_count'][::-1], color='#2563EB')\n",
    "ax.set_xlabel('Number of Job Postings')\n",
    "ax.set_title('Top 20 Companies by Posting Volume')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Company distribution by posting count (long-tail analysis)\n",
    "company_dist = con.execute(\"\"\"\n",
    "    SELECT job_count, COUNT(*) as num_companies\n",
    "    FROM (\n",
    "        SELECT company_name, COUNT(*) as job_count\n",
    "        FROM jobs_enriched\n",
    "        WHERE company_name IS NOT NULL\n",
    "        GROUP BY company_name\n",
    "    )\n",
    "    GROUP BY job_count\n",
    "    ORDER BY job_count\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.scatter(company_dist['job_count'], company_dist['num_companies'], alpha=0.6, color='#8B5CF6', s=20)\n",
    "ax.set_xlabel('Number of Job Postings per Company')\n",
    "ax.set_ylabel('Number of Companies')\n",
    "ax.set_title('Long-Tail Distribution: Companies by Posting Count')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "total_companies = con.execute(\"SELECT COUNT(DISTINCT company_name) FROM jobs_enriched WHERE company_name IS NOT NULL\").fetchone()[0]\n",
    "single_post = company_dist[company_dist['job_count'] == 1]['num_companies'].iloc[0] if 1 in company_dist['job_count'].values else 0\n",
    "print(f\"Total unique companies: {total_companies:,}\")\n",
    "print(f\"Companies with only 1 posting: {single_post:,} ({single_post/total_companies*100:.1f}%)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Top 15 highest-paying companies (minimum 5 postings)\n",
    "high_pay_companies = con.execute(\"\"\"\n",
    "    SELECT company_name,\n",
    "           AVG(avg_salary) as mean_salary,\n",
    "           PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY avg_salary) as median_salary,\n",
    "           COUNT(*) as job_count\n",
    "    FROM jobs_enriched\n",
    "    WHERE company_name IS NOT NULL AND avg_salary > 0 AND avg_salary < 50000\n",
    "    GROUP BY company_name\n",
    "    HAVING COUNT(*) >= 5\n",
    "    ORDER BY mean_salary DESC\n",
    "    LIMIT 15\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = range(len(high_pay_companies))\n",
    "width = 0.35\n",
    "ax.bar([i - width/2 for i in x], high_pay_companies['mean_salary'], width, label='Mean', color='#2563EB')\n",
    "ax.bar([i + width/2 for i in x], high_pay_companies['median_salary'], width, label='Median', color='#10B981')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(high_pay_companies['company_name'], rotation=45, ha='right')\n",
    "ax.set_ylabel('Salary ($)')\n",
    "ax.set_title('Top 15 Highest-Paying Companies (min 5 postings)')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Engagement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Views vs applications scatter (colored by salary)\n",
    "engagement = con.execute(\"\"\"\n",
    "    SELECT views, applications, avg_salary, salary_band\n",
    "    FROM jobs_enriched\n",
    "    WHERE views IS NOT NULL AND views > 0\n",
    "      AND applications IS NOT NULL AND applications >= 0\n",
    "      AND views < 10000 AND applications < 1000\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "scatter = ax.scatter(engagement['views'], engagement['applications'],\n",
    "                     c=engagement['avg_salary'], cmap='viridis',\n",
    "                     alpha=0.3, s=10)\n",
    "plt.colorbar(scatter, label='Average Salary ($)')\n",
    "ax.set_xlabel('Views')\n",
    "ax.set_ylabel('Applications')\n",
    "ax.set_title('Views vs Applications (colored by salary)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Application rate distribution\n",
    "app_rate = con.execute(\"\"\"\n",
    "    SELECT application_rate\n",
    "    FROM jobs_enriched\n",
    "    WHERE application_rate IS NOT NULL AND application_rate > 0 AND application_rate < 1\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(app_rate['application_rate'], bins=50, color='#10B981', edgecolor='white', alpha=0.8)\n",
    "ax.set_xlabel('Application Rate (applications / views)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Application Rate Distribution')\n",
    "ax.axvline(app_rate['application_rate'].median(), color='#EF4444', linestyle='--',\n",
    "           label=f\"Median: {app_rate['application_rate'].median():.3f}\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Application rate by category\n",
    "cat_app_rate = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        jc.category_name,\n",
    "        AVG(je.application_rate) as avg_app_rate,\n",
    "        COUNT(*) as job_count\n",
    "    FROM jobs_categories jc\n",
    "    JOIN jobs_enriched je ON jc.job_id = je.job_id\n",
    "    WHERE je.application_rate IS NOT NULL AND je.application_rate > 0 AND je.application_rate < 1\n",
    "      AND jc.category_name IS NOT NULL\n",
    "    GROUP BY jc.category_name\n",
    "    HAVING COUNT(*) >= 100\n",
    "    ORDER BY avg_app_rate DESC\n",
    "    LIMIT 15\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.barh(cat_app_rate['category_name'][::-1], cat_app_rate['avg_app_rate'][::-1], color='#8B5CF6')\n",
    "ax.set_xlabel('Average Application Rate')\n",
    "ax.set_title('Application Rate by Category (min 100 postings)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engagement Insights\n",
    "\n",
    "- **Positive correlation:** Views and applications show a clear positive relationship, but the scatter reveals significant variance — some high-view jobs get few applications, suggesting role-specific barriers.\n",
    "- **Low application rates:** Most jobs have application rates well below 10%, indicating that job seekers are selective or that many postings attract passive viewers.\n",
    "- **Category variation:** Application rates vary significantly by category, revealing which sectors face talent shortages (low rates) vs. high competition (high rates).\n",
    "- **Dashboard design:** The application rate metric (applications/views) is included in the dashboard as a \"competition indicator\" to help users identify less competitive opportunities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Key Findings Summary\n",
    "\n",
    "### Data Quality\n",
    "- Dataset contains 1M+ job postings with 22 columns\n",
    "- Core fields have zero null rates; `occupationId` is 100% null and excluded\n",
    "- JSON fields (`categories`) require careful parsing; `positionLevels` and `employmentTypes` are plain strings\n",
    "- Salary data is clean with no invalid ranges (max < min)\n",
    "\n",
    "### Salary Insights\n",
    "- Distribution is right-skewed — median is more representative than mean\n",
    "- The $50K salary cap effectively removes extreme outliers while preserving 99%+ of data\n",
    "- Clear salary progression across experience bands validates the 4-band classification\n",
    "- Significant salary variation across categories — some pay 2-3x more than others\n",
    "\n",
    "### Market Structure\n",
    "- Long-tail company distribution: a few large employers dominate posting volume\n",
    "- Top 20 categories account for the majority of all categorized postings\n",
    "- Most jobs are tagged with 1-3 categories\n",
    "\n",
    "### Temporal Patterns\n",
    "- Strong weekday bias in posting activity\n",
    "- Seasonal hiring patterns visible at quarterly granularity\n",
    "- Salary levels remain relatively stable over time\n",
    "\n",
    "### Engagement Patterns\n",
    "- Most jobs have low application rates (<10%)\n",
    "- Positive but noisy correlation between views and applications\n",
    "- Application rates vary significantly by category\n",
    "\n",
    "### Dashboard Design Decisions Informed by EDA\n",
    "1. **$50K salary cap** — removes outliers without losing meaningful data\n",
    "2. **6 salary bands** — match natural clusters in the distribution\n",
    "3. **4 experience bands** — align with clear salary progression steps\n",
    "4. **Application rate as competition metric** — provides actionable signal\n",
    "5. **Monthly granularity for trends** — balances detail with readability\n",
    "6. **Category-first navigation** — categories have the best coverage\n",
    "7. **Mean + Median presentation** — both metrics shown to account for skewness\n",
    "8. **Company comparison mode** — long-tail distribution means top employers are meaningful benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Clean up\n",
    "con.close()\n",
    "print('EDA complete. All views and connections closed.')"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}